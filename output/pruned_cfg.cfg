#-1
[net]
scales=.1,.1
burn_in=1000
momentum=0.9
hue=.1
policy=steps
learning_rate=0.0005
steps=400000,450000
width=416
channels=3
decay=0.0005
batch=64
subdivisions=4
height=416
max_batches=500200
exposure=1.5
angle=5
saturation=1.5


#0
[convolutional]
pad=1
filters=13
stride=1
activation=leaky
size=3
batch_normalize=1


#1
[maxpool]
stride=2
size=2


#2
[convolutional]
pad=1
filters=26
stride=1
activation=leaky
size=3
batch_normalize=1


#3
[maxpool]
stride=2
size=2


#4
[convolutional]
pad=1
filters=51
stride=1
activation=leaky
size=3
batch_normalize=1


#5
[maxpool]
stride=2
size=2


#6
[convolutional]
pad=1
filters=102
stride=1
activation=leaky
size=3
batch_normalize=1


#7
[maxpool]
stride=2
size=2


#8
[convolutional]
pad=1
filters=205
stride=1
activation=leaky
size=3
batch_normalize=1


#9
[maxpool]
stride=2
size=2


#10
[convolutional]
pad=1
filters=410
stride=1
activation=leaky
size=3
batch_normalize=1


#11
[maxpool]
stride=1
size=2


#12
[convolutional]
pad=1
filters=819
stride=1
activation=leaky
size=3
batch_normalize=1


#13
[convolutional]
pad=1
filters=205
stride=1
activation=leaky
size=1
batch_normalize=1


#14
[convolutional]
pad=1
filters=410
stride=1
activation=leaky
size=3
batch_normalize=1


#15
[convolutional]
stride=1
size=1
activation=linear
filters=75
pad=1


#16
[yolo]
num=6
truth_thresh=1
anchors=43,65, 99,148, 117,261, 291,192, 204,349, 364,358
classes=20
mask=3,4,5
random=1
jitter=.3
ignore_thresh=.5


#17
[route]
layers=-4


#18
[convolutional]
pad=1
filters=102
stride=1
activation=leaky
size=1
batch_normalize=1


#19
[upsample]
stride=2


#20
[route]
layers=-1, 8


#21
[convolutional]
pad=1
filters=205
stride=1
activation=leaky
size=3
batch_normalize=1


#22
[convolutional]
stride=1
size=1
activation=linear
filters=75
pad=1


#23
[yolo]
num=6
truth_thresh=1
anchors=43,65, 99,148, 117,261, 291,192, 204,349, 364,358
classes=20
mask=0,1,2
random=1
jitter=.3
ignore_thresh=.5


